{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panduan ETL Data GDELT\n",
    "\n",
    "Selamat datang di halaman panduan ETL data GDELT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download\n",
    "\n",
    "Berikut adalah contoh script untuk mengunduh data GDELT dengan country code ID. Selanjutnya dari csv bisa dipindah ke mysql. Disadur dari [Github pak Guntur Budi](https://github.com/gunturbudi/digital-talent/blob/master/RETRIEVE%20GDELT%20DATA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "\n",
    "gdelt_base_url = 'http://data.gdeltproject.org/events/'\n",
    "\n",
    "# get the list of all the links on the gdelt file page\n",
    "page = requests.get(gdelt_base_url+'index.html')\n",
    "doc = lh.fromstring(page.content)\n",
    "link_list = doc.xpath(\"//*/ul/li/a/@href\")\n",
    "\n",
    "# separate out those links that begin with four digits\n",
    "file_list = [x for x in link_list if str.isdigit(x[0:4])]\n",
    "print(file_list)\n",
    "\n",
    "infilecounter = 0\n",
    "outfilecounter = 0\n",
    "\n",
    "import os.path\n",
    "import urllib\n",
    "import zipfile\n",
    "import glob\n",
    "import operator\n",
    "\n",
    "local_path = os.getcwd()\n",
    "\n",
    "fips_country_code = 'ID'\n",
    "\n",
    "for compressed_file in file_list[infilecounter:]:\n",
    "    print(compressed_file)\n",
    "\n",
    "    # if we dont have the compressed file stored locally, go get it. Keep trying if necessary.\n",
    "    while not os.path.isfile(local_path + compressed_file):\n",
    "        print('downloading, '),\n",
    "        urllib.request.urlretrieve(url=gdelt_base_url + compressed_file,\n",
    "                           filename=local_path + compressed_file)\n",
    "\n",
    "    # extract the contents of the compressed file to a temporary directory\n",
    "    print('extracting,'),\n",
    "    z = zipfile.ZipFile(file=local_path + compressed_file, mode='r')\n",
    "    z.extractall(path=local_path + 'tmp/')\n",
    "\n",
    "    # parse each of the csv files in the working directory,\n",
    "    print('parsing,'),\n",
    "    for infile_name in glob.glob(local_path + 'tmp/*'):\n",
    "        outfile_name = local_path + 'gdelt_id/' + fips_country_code + '%04i.tsv' % outfilecounter\n",
    "\n",
    "        # open the infile and outfile\n",
    "        with open(infile_name, mode='r', encoding='utf-8') as infile, open(outfile_name, mode='w') as outfile:\n",
    "            for line in infile:\n",
    "                # extract lines with our interest country code\n",
    "                # Try and except to pass trouble data\n",
    "                try:\n",
    "                    # We extract only the lines where there is relation about Indonesia (ID)\n",
    "                    if fips_country_code in operator.itemgetter(51, 37, 44)(line.split('\\t')):\n",
    "                        outfile.write(line)\n",
    "                except:\n",
    "                    pass\n",
    "            outfilecounter += 1\n",
    "        # delete the temporary file\n",
    "        os.remove(infile_name)\n",
    "    infilecounter += 1\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simpan ke MySQL\n",
    "Agar data bisa diakses lokal dengan mudah, kita bisa menyimpannya dalam database MySQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Bangun koneksi ke MySQL lokal\n",
    "Silakan buka phpMyAdmin atau program SQL favorit anda (HeidiSQL, Laragon), lalu buat database dengan nama 'gdelt_content_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "username = 'root'\n",
    "password = ''\n",
    "database = 'gdelt_content_id'\n",
    "\n",
    "# Create Connection to database\n",
    "engine = create_engine('mysql+pymysql://'+username+':'+password+'@'+host+':'+port+'/'+database)\n",
    "'''engine = create_engine('mysql+pymysql://root: @localhost:3306/gdelt_content_id')'''\n",
    "\n",
    "def run(sql):\n",
    "    df = pd.read_sql_query(sql, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. List Data dalam Folder\n",
    "Di bagian ini, kita membaca data GDELT harian (tsv) dalam folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "folder_id = './gdelt_id/'\n",
    "files = [f for f in listdir(folder_id) if isfile(join(folder_id, f))]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open first file for sanity check\n",
    "df_awal = pd.read_csv(folder_id + files[0],sep=\"\\t\")\n",
    "df_awal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Langsung simpan ke MySQL\n",
    "Untuk menyimpan data ke SQL, kita update data tabelnya untuk setiap file tsv yang ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read header / column names\n",
    "colnames = list(pd.read_excel('CSV.header.fieldids.xlsx', sheet_name='CSV.header.dailyupdates'))\n",
    "\n",
    "for berkas in files:\n",
    "    print('Extracting ' + berkas)\n",
    "    df_satuan = pd.DataFrame()\n",
    "    \n",
    "    # Important: If your ID0000.tsv contains header, you can delete the header\n",
    "    df_satuan = pd.read_csv(folder_id + berkas, sep=\"\\t\", names= colnames)\n",
    "    df_satuan.to_sql(name = database, con = engine, if_exists = 'append', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
