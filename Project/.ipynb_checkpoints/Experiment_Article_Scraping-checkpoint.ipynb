{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from newspaper import Article\n",
    "\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "username = 'root'\n",
    "password = ''\n",
    "database = 'gdelt_content_id'\n",
    "\n",
    "# Create Connection to database\n",
    "# engine = create_engine('mysql+pymysql://'+username+\n",
    "# ':'+password+'@'+host+':'+port+'/'+database)\n",
    "\n",
    "# Note: We use pymysql instead of sqlalchemy because sqlalchemy\n",
    "# somehow don't allow the text query. Strange bug.\n",
    "conn = pymysql.connect(\n",
    "    host=host,\n",
    "    port=int(port),\n",
    "    user=username,\n",
    "    passwd=password,\n",
    "    db=database,\n",
    "    charset='utf8mb4')\n",
    "'''engine = create_engine('mysql+pymysql://root: @localhost:3306\n",
    "/gdelt_content_id')'''\n",
    "\n",
    "def run(sql):\n",
    "    df = pd.read_sql_query(sql, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_startup = run(\"SELECT GLOBALEVENTID, SQLDATE, Year, SOURCEURL FROM startup_indonesia WHERE year = 2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_baris = data_startup.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping article 1 of 402\n",
      "Scraping article 2 of 402\n",
      "Scraping article 3 of 402\n",
      "Scraping article 4 of 402\n",
      "Scraping article 5 of 402\n",
      "Scraping article 6 of 402\n",
      "Scraping article 7 of 402\n",
      "Scraping article 8 of 402\n",
      "Scraping article 9 of 402\n",
      "Scraping article 10 of 402\n",
      "Scraping article 11 of 402\n",
      "Error scraping article 11 of 402\n",
      "Scraping article 12 of 402\n",
      "Scraping article 13 of 402\n",
      "Scraping article 14 of 402\n",
      "Scraping article 15 of 402\n",
      "Scraping article 16 of 402\n",
      "Scraping article 17 of 402\n",
      "Scraping article 18 of 402\n",
      "Error scraping article 18 of 402\n",
      "Scraping article 19 of 402\n",
      "Scraping article 20 of 402\n",
      "Scraping article 21 of 402\n",
      "Scraping article 22 of 402\n",
      "Scraping article 23 of 402\n",
      "Scraping article 24 of 402\n",
      "Scraping article 25 of 402\n",
      "Scraping article 26 of 402\n",
      "Scraping article 27 of 402\n",
      "Scraping article 28 of 402\n",
      "Scraping article 29 of 402\n",
      "Scraping article 30 of 402\n",
      "Scraping article 31 of 402\n",
      "Scraping article 32 of 402\n",
      "Scraping article 33 of 402\n",
      "Scraping article 34 of 402\n",
      "Scraping article 35 of 402\n",
      "Scraping article 36 of 402\n",
      "Scraping article 37 of 402\n",
      "Scraping article 38 of 402\n",
      "Scraping article 39 of 402\n",
      "Scraping article 40 of 402\n",
      "Scraping article 41 of 402\n",
      "Scraping article 42 of 402\n",
      "Scraping article 43 of 402\n",
      "Scraping article 44 of 402\n",
      "Scraping article 45 of 402\n",
      "Scraping article 46 of 402\n",
      "Scraping article 47 of 402\n",
      "Scraping article 48 of 402\n",
      "Scraping article 49 of 402\n",
      "Scraping article 50 of 402\n",
      "Scraping article 51 of 402\n",
      "Scraping article 52 of 402\n",
      "Scraping article 53 of 402\n",
      "Scraping article 54 of 402\n",
      "Scraping article 55 of 402\n",
      "Scraping article 56 of 402\n",
      "Scraping article 57 of 402\n",
      "Scraping article 58 of 402\n",
      "Scraping article 59 of 402\n",
      "Scraping article 60 of 402\n",
      "Scraping article 61 of 402\n",
      "Scraping article 62 of 402\n",
      "Scraping article 63 of 402\n",
      "Scraping article 64 of 402\n",
      "Scraping article 65 of 402\n",
      "Scraping article 66 of 402\n",
      "Scraping article 67 of 402\n",
      "Scraping article 68 of 402\n",
      "Scraping article 69 of 402\n",
      "Scraping article 70 of 402\n",
      "Scraping article 71 of 402\n",
      "Scraping article 72 of 402\n",
      "Scraping article 73 of 402\n",
      "Scraping article 74 of 402\n",
      "Scraping article 75 of 402\n",
      "Scraping article 76 of 402\n",
      "Scraping article 77 of 402\n",
      "Scraping article 78 of 402\n",
      "Scraping article 79 of 402\n",
      "Scraping article 80 of 402\n",
      "Scraping article 81 of 402\n",
      "Scraping article 82 of 402\n",
      "Scraping article 83 of 402\n",
      "Scraping article 84 of 402\n",
      "Scraping article 85 of 402\n",
      "Scraping article 86 of 402\n",
      "Scraping article 87 of 402\n",
      "Scraping article 88 of 402\n",
      "Scraping article 89 of 402\n",
      "Scraping article 90 of 402\n",
      "Scraping article 91 of 402\n",
      "Scraping article 92 of 402\n",
      "Scraping article 93 of 402\n",
      "Error scraping article 93 of 402\n",
      "Scraping article 94 of 402\n",
      "Scraping article 95 of 402\n",
      "Scraping article 96 of 402\n",
      "Scraping article 97 of 402\n",
      "Scraping article 98 of 402\n",
      "Scraping article 99 of 402\n",
      "Scraping article 100 of 402\n",
      "Scraping article 101 of 402\n",
      "Error scraping article 101 of 402\n",
      "Scraping article 102 of 402\n",
      "Scraping article 103 of 402\n",
      "Scraping article 104 of 402\n",
      "Error scraping article 104 of 402\n",
      "Scraping article 105 of 402\n",
      "Scraping article 106 of 402\n",
      "Scraping article 107 of 402\n",
      "Scraping article 108 of 402\n",
      "Scraping article 109 of 402\n",
      "Scraping article 110 of 402\n",
      "Scraping article 111 of 402\n",
      "Scraping article 112 of 402\n",
      "Scraping article 113 of 402\n",
      "Scraping article 114 of 402\n",
      "Scraping article 115 of 402\n",
      "Scraping article 116 of 402\n",
      "Scraping article 117 of 402\n",
      "Scraping article 118 of 402\n",
      "Scraping article 119 of 402\n",
      "Scraping article 120 of 402\n",
      "Scraping article 121 of 402\n",
      "Scraping article 122 of 402\n",
      "Scraping article 123 of 402\n",
      "Scraping article 124 of 402\n",
      "Scraping article 125 of 402\n",
      "Scraping article 126 of 402\n",
      "Scraping article 127 of 402\n",
      "Scraping article 128 of 402\n",
      "Scraping article 129 of 402\n",
      "Scraping article 130 of 402\n",
      "Scraping article 131 of 402\n",
      "Scraping article 132 of 402\n",
      "Scraping article 133 of 402\n",
      "Scraping article 134 of 402\n",
      "Scraping article 135 of 402\n",
      "Scraping article 136 of 402\n",
      "Scraping article 137 of 402\n",
      "Scraping article 138 of 402\n",
      "Scraping article 139 of 402\n",
      "Error scraping article 139 of 402\n",
      "Scraping article 140 of 402\n",
      "Scraping article 141 of 402\n",
      "Scraping article 142 of 402\n",
      "Scraping article 143 of 402\n",
      "Scraping article 144 of 402\n",
      "Scraping article 145 of 402\n",
      "Scraping article 146 of 402\n",
      "Scraping article 147 of 402\n",
      "Scraping article 148 of 402\n",
      "Scraping article 149 of 402\n",
      "Scraping article 150 of 402\n",
      "Scraping article 151 of 402\n",
      "Scraping article 152 of 402\n",
      "Scraping article 153 of 402\n",
      "Scraping article 154 of 402\n",
      "Scraping article 155 of 402\n",
      "Scraping article 156 of 402\n",
      "Scraping article 157 of 402\n",
      "Error scraping article 157 of 402\n",
      "Scraping article 158 of 402\n",
      "Scraping article 159 of 402\n",
      "Scraping article 160 of 402\n",
      "Scraping article 161 of 402\n",
      "Scraping article 162 of 402\n",
      "Scraping article 163 of 402\n",
      "Scraping article 164 of 402\n",
      "Scraping article 165 of 402\n",
      "Scraping article 166 of 402\n",
      "Error scraping article 166 of 402\n",
      "Scraping article 167 of 402\n",
      "Scraping article 168 of 402\n",
      "Scraping article 169 of 402\n",
      "Scraping article 170 of 402\n",
      "Scraping article 171 of 402\n",
      "Scraping article 172 of 402\n",
      "Scraping article 173 of 402\n",
      "Scraping article 174 of 402\n",
      "Scraping article 175 of 402\n",
      "Scraping article 176 of 402\n",
      "Scraping article 177 of 402\n",
      "Scraping article 178 of 402\n",
      "Scraping article 179 of 402\n",
      "Scraping article 180 of 402\n",
      "Scraping article 181 of 402\n",
      "Scraping article 182 of 402\n",
      "Scraping article 183 of 402\n",
      "Scraping article 184 of 402\n",
      "Error scraping article 184 of 402\n",
      "Scraping article 185 of 402\n",
      "Scraping article 186 of 402\n",
      "Scraping article 187 of 402\n",
      "Scraping article 188 of 402\n",
      "Scraping article 189 of 402\n",
      "Scraping article 190 of 402\n",
      "Scraping article 191 of 402\n",
      "Scraping article 192 of 402\n",
      "Scraping article 193 of 402\n",
      "Scraping article 194 of 402\n",
      "Scraping article 195 of 402\n",
      "Scraping article 196 of 402\n",
      "Scraping article 197 of 402\n",
      "Scraping article 198 of 402\n",
      "Scraping article 199 of 402\n",
      "Scraping article 200 of 402\n",
      "Scraping article 201 of 402\n",
      "Scraping article 202 of 402\n",
      "Scraping article 203 of 402\n",
      "Error scraping article 203 of 402\n",
      "Scraping article 204 of 402\n",
      "Scraping article 205 of 402\n",
      "Scraping article 206 of 402\n",
      "Scraping article 207 of 402\n",
      "Scraping article 208 of 402\n",
      "Scraping article 209 of 402\n",
      "Scraping article 210 of 402\n",
      "Scraping article 211 of 402\n",
      "Scraping article 212 of 402\n",
      "Scraping article 213 of 402\n",
      "Scraping article 214 of 402\n",
      "Scraping article 215 of 402\n",
      "Scraping article 216 of 402\n",
      "Scraping article 217 of 402\n",
      "Scraping article 218 of 402\n",
      "Scraping article 219 of 402\n",
      "Scraping article 220 of 402\n",
      "Scraping article 221 of 402\n",
      "Scraping article 222 of 402\n",
      "Scraping article 223 of 402\n",
      "Scraping article 224 of 402\n",
      "Scraping article 225 of 402\n",
      "Scraping article 226 of 402\n",
      "Scraping article 227 of 402\n",
      "Error scraping article 227 of 402\n",
      "Scraping article 228 of 402\n",
      "Scraping article 229 of 402\n",
      "Scraping article 230 of 402\n",
      "Scraping article 231 of 402\n",
      "Scraping article 232 of 402\n",
      "Scraping article 233 of 402\n",
      "Scraping article 234 of 402\n",
      "Scraping article 235 of 402\n",
      "Error scraping article 235 of 402\n",
      "Scraping article 236 of 402\n",
      "Scraping article 237 of 402\n",
      "Error scraping article 237 of 402\n",
      "Scraping article 238 of 402\n",
      "Scraping article 239 of 402\n",
      "Scraping article 240 of 402\n",
      "Scraping article 241 of 402\n",
      "Scraping article 242 of 402\n",
      "Error scraping article 242 of 402\n",
      "Scraping article 243 of 402\n",
      "Scraping article 244 of 402\n",
      "Scraping article 245 of 402\n",
      "Scraping article 246 of 402\n",
      "Scraping article 247 of 402\n",
      "Scraping article 248 of 402\n",
      "Scraping article 249 of 402\n",
      "Scraping article 250 of 402\n",
      "Scraping article 251 of 402\n",
      "Scraping article 252 of 402\n",
      "Scraping article 253 of 402\n",
      "Scraping article 254 of 402\n",
      "Scraping article 255 of 402\n",
      "Scraping article 256 of 402\n",
      "Scraping article 257 of 402\n",
      "Scraping article 258 of 402\n",
      "Scraping article 259 of 402\n",
      "Scraping article 260 of 402\n",
      "Scraping article 261 of 402\n",
      "Scraping article 262 of 402\n",
      "Scraping article 263 of 402\n",
      "Scraping article 264 of 402\n",
      "Scraping article 265 of 402\n",
      "Scraping article 266 of 402\n",
      "Scraping article 267 of 402\n",
      "Scraping article 268 of 402\n",
      "Scraping article 269 of 402\n",
      "Scraping article 270 of 402\n",
      "Scraping article 271 of 402\n",
      "Scraping article 272 of 402\n",
      "Scraping article 273 of 402\n",
      "Scraping article 274 of 402\n",
      "Scraping article 275 of 402\n",
      "Scraping article 276 of 402\n",
      "Scraping article 277 of 402\n",
      "Scraping article 278 of 402\n",
      "Scraping article 279 of 402\n",
      "Scraping article 280 of 402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping article 281 of 402\n",
      "Scraping article 282 of 402\n",
      "Scraping article 283 of 402\n",
      "Scraping article 284 of 402\n",
      "Scraping article 285 of 402\n",
      "Scraping article 286 of 402\n",
      "Scraping article 287 of 402\n",
      "Scraping article 288 of 402\n",
      "Scraping article 289 of 402\n",
      "Scraping article 290 of 402\n",
      "Scraping article 291 of 402\n",
      "Scraping article 292 of 402\n",
      "Scraping article 293 of 402\n",
      "Scraping article 294 of 402\n",
      "Scraping article 295 of 402\n",
      "Scraping article 296 of 402\n",
      "Scraping article 297 of 402\n",
      "Scraping article 298 of 402\n",
      "Scraping article 299 of 402\n",
      "Scraping article 300 of 402\n",
      "Scraping article 301 of 402\n",
      "Scraping article 302 of 402\n",
      "Scraping article 303 of 402\n",
      "Scraping article 304 of 402\n",
      "Scraping article 305 of 402\n",
      "Scraping article 306 of 402\n",
      "Scraping article 307 of 402\n",
      "Scraping article 308 of 402\n",
      "Scraping article 309 of 402\n",
      "Scraping article 310 of 402\n",
      "Scraping article 311 of 402\n",
      "Scraping article 312 of 402\n",
      "Scraping article 313 of 402\n",
      "Scraping article 314 of 402\n",
      "Scraping article 315 of 402\n",
      "Scraping article 316 of 402\n",
      "Error scraping article 316 of 402\n",
      "Scraping article 317 of 402\n",
      "Scraping article 318 of 402\n",
      "Scraping article 319 of 402\n",
      "Scraping article 320 of 402\n",
      "Scraping article 321 of 402\n",
      "Scraping article 322 of 402\n",
      "Scraping article 323 of 402\n",
      "Scraping article 324 of 402\n",
      "Scraping article 325 of 402\n",
      "Scraping article 326 of 402\n",
      "Scraping article 327 of 402\n",
      "Scraping article 328 of 402\n",
      "Scraping article 329 of 402\n",
      "Error scraping article 329 of 402\n",
      "Scraping article 330 of 402\n",
      "Error scraping article 330 of 402\n",
      "Scraping article 331 of 402\n",
      "Scraping article 332 of 402\n",
      "Scraping article 333 of 402\n",
      "Scraping article 334 of 402\n",
      "Scraping article 335 of 402\n",
      "Scraping article 336 of 402\n",
      "Scraping article 337 of 402\n",
      "Scraping article 338 of 402\n",
      "Scraping article 339 of 402\n",
      "Scraping article 340 of 402\n",
      "Error scraping article 340 of 402\n",
      "Scraping article 341 of 402\n",
      "Scraping article 342 of 402\n",
      "Scraping article 343 of 402\n",
      "Scraping article 344 of 402\n",
      "Scraping article 345 of 402\n",
      "Scraping article 346 of 402\n",
      "Scraping article 347 of 402\n",
      "Scraping article 348 of 402\n",
      "Scraping article 349 of 402\n",
      "Scraping article 350 of 402\n",
      "Error scraping article 350 of 402\n",
      "Scraping article 351 of 402\n",
      "Scraping article 352 of 402\n",
      "Scraping article 353 of 402\n",
      "Scraping article 354 of 402\n",
      "Scraping article 355 of 402\n",
      "Scraping article 356 of 402\n",
      "Scraping article 357 of 402\n",
      "Scraping article 358 of 402\n",
      "Scraping article 359 of 402\n",
      "Scraping article 360 of 402\n",
      "Scraping article 361 of 402\n",
      "Scraping article 362 of 402\n",
      "Scraping article 363 of 402\n",
      "Scraping article 364 of 402\n",
      "Scraping article 365 of 402\n",
      "Scraping article 366 of 402\n",
      "Scraping article 367 of 402\n",
      "Scraping article 368 of 402\n",
      "Scraping article 369 of 402\n",
      "Scraping article 370 of 402\n",
      "Scraping article 371 of 402\n",
      "Scraping article 372 of 402\n",
      "Scraping article 373 of 402\n",
      "Scraping article 374 of 402\n",
      "Scraping article 375 of 402\n",
      "Scraping article 376 of 402\n",
      "Error scraping article 376 of 402\n",
      "Scraping article 377 of 402\n",
      "Scraping article 378 of 402\n",
      "Scraping article 379 of 402\n",
      "Scraping article 380 of 402\n",
      "Scraping article 381 of 402\n",
      "Scraping article 382 of 402\n",
      "Error scraping article 382 of 402\n",
      "Scraping article 383 of 402\n",
      "Scraping article 384 of 402\n",
      "Error scraping article 384 of 402\n",
      "Scraping article 385 of 402\n",
      "Scraping article 386 of 402\n",
      "Scraping article 387 of 402\n",
      "Scraping article 388 of 402\n",
      "Scraping article 389 of 402\n",
      "Scraping article 390 of 402\n",
      "Error scraping article 390 of 402\n",
      "Scraping article 391 of 402\n",
      "Scraping article 392 of 402\n",
      "Scraping article 393 of 402\n",
      "Scraping article 394 of 402\n",
      "Scraping article 395 of 402\n",
      "Scraping article 396 of 402\n",
      "Scraping article 397 of 402\n",
      "Scraping article 398 of 402\n",
      "Scraping article 399 of 402\n",
      "Scraping article 400 of 402\n",
      "Scraping article 401 of 402\n",
      "Scraping article 402 of 402\n"
     ]
    }
   ],
   "source": [
    "isi_berita = list()\n",
    "i = 1\n",
    "for link in data_startup.SOURCEURL:\n",
    "    print(\"Scraping article \" + str(i) + \" of \" + str(total_baris))\n",
    "    berita = Article(link)\n",
    "    try:\n",
    "        berita.download()\n",
    "        berita.parse()\n",
    "        isi_berita.append(berita.text)\n",
    "    except:\n",
    "        print(\"Error scraping article \" + str(i) + \" of \" + str(total_baris))\n",
    "        isi_berita.append(link)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(isi_berita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(isi_berita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_startup['ARTICLEURL'] = pd.Series(isi_berita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 5)\n"
     ]
    }
   ],
   "source": [
    "data_startup.head()\n",
    "print(data_startup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBALEVENTID</th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>Year</th>\n",
       "      <th>SOURCEURL</th>\n",
       "      <th>ARTICLEURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>795776971</td>\n",
       "      <td>20180919</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>794276788</td>\n",
       "      <td>20181013</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>785918381</td>\n",
       "      <td>20180910</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://www.en.netralnews.com/news/business/rea...</td>\n",
       "      <td>http://www.en.netralnews.com/news/business/rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>784607887</td>\n",
       "      <td>20180905</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://english.vietnamnet.vn/fms/business/207...</td>\n",
       "      <td>https://english.vietnamnet.vn/fms/business/207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>784110183</td>\n",
       "      <td>20180903</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.opengovasia.com/article/the-role-o...</td>\n",
       "      <td>https://www.opengovasia.com/article/the-role-o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GLOBALEVENTID   SQLDATE  Year  \\\n",
       "10       795776971  20180919  2018   \n",
       "17       794276788  20181013  2018   \n",
       "92       785918381  20180910  2018   \n",
       "100      784607887  20180905  2018   \n",
       "103      784110183  20180903  2018   \n",
       "\n",
       "                                             SOURCEURL  \\\n",
       "10   https://economictimes.indiatimes.com/small-biz...   \n",
       "17   https://economictimes.indiatimes.com/small-biz...   \n",
       "92   http://www.en.netralnews.com/news/business/rea...   \n",
       "100  https://english.vietnamnet.vn/fms/business/207...   \n",
       "103  https://www.opengovasia.com/article/the-role-o...   \n",
       "\n",
       "                                            ARTICLEURL  \n",
       "10   https://economictimes.indiatimes.com/small-biz...  \n",
       "17   https://economictimes.indiatimes.com/small-biz...  \n",
       "92   http://www.en.netralnews.com/news/business/rea...  \n",
       "100  https://english.vietnamnet.vn/fms/business/207...  \n",
       "103  https://www.opengovasia.com/article/the-role-o...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_incom = data_startup.loc[data_startup['ARTICLEURL'] == data_startup['SOURCEURL']]\n",
    "data_null = data_startup.loc[data_startup['ARTICLEURL'] == '']\n",
    "data_incom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBALEVENTID</th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>Year</th>\n",
       "      <th>SOURCEURL</th>\n",
       "      <th>ARTICLEURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>786997689</td>\n",
       "      <td>20180914</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.opengovasia.com/indonesia-furthers...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>782286669</td>\n",
       "      <td>20180827</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/startups/pages/118016605-go...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>782319837</td>\n",
       "      <td>20180827</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.thepaypers.com/mobile-payments/jd-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>774333479</td>\n",
       "      <td>20180724</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/pages/116649609-tech-in-asi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>774019331</td>\n",
       "      <td>20180723</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/startups/pages/116605809-an...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GLOBALEVENTID   SQLDATE  Year  \\\n",
       "77       786997689  20180914  2018   \n",
       "126      782286669  20180827  2018   \n",
       "128      782319837  20180827  2018   \n",
       "162      774333479  20180724  2018   \n",
       "163      774019331  20180723  2018   \n",
       "\n",
       "                                             SOURCEURL ARTICLEURL  \n",
       "77   https://www.opengovasia.com/indonesia-furthers...             \n",
       "126  http://sglinks.com/startups/pages/118016605-go...             \n",
       "128  https://www.thepaypers.com/mobile-payments/jd-...             \n",
       "162  http://sglinks.com/pages/116649609-tech-in-asi...             \n",
       "163  http://sglinks.com/startups/pages/116605809-an...             "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_null.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBALEVENTID</th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>Year</th>\n",
       "      <th>SOURCEURL</th>\n",
       "      <th>ARTICLEURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>795776971</td>\n",
       "      <td>20180919</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>794276788</td>\n",
       "      <td>20181013</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>785918381</td>\n",
       "      <td>20180910</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://www.en.netralnews.com/news/business/rea...</td>\n",
       "      <td>http://www.en.netralnews.com/news/business/rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>784607887</td>\n",
       "      <td>20180905</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://english.vietnamnet.vn/fms/business/207...</td>\n",
       "      <td>https://english.vietnamnet.vn/fms/business/207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>784110183</td>\n",
       "      <td>20180903</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.opengovasia.com/article/the-role-o...</td>\n",
       "      <td>https://www.opengovasia.com/article/the-role-o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GLOBALEVENTID   SQLDATE  Year  \\\n",
       "10       795776971  20180919  2018   \n",
       "17       794276788  20181013  2018   \n",
       "92       785918381  20180910  2018   \n",
       "100      784607887  20180905  2018   \n",
       "103      784110183  20180903  2018   \n",
       "\n",
       "                                             SOURCEURL  \\\n",
       "10   https://economictimes.indiatimes.com/small-biz...   \n",
       "17   https://economictimes.indiatimes.com/small-biz...   \n",
       "92   http://www.en.netralnews.com/news/business/rea...   \n",
       "100  https://english.vietnamnet.vn/fms/business/207...   \n",
       "103  https://www.opengovasia.com/article/the-role-o...   \n",
       "\n",
       "                                            ARTICLEURL  \n",
       "10   https://economictimes.indiatimes.com/small-biz...  \n",
       "17   https://economictimes.indiatimes.com/small-biz...  \n",
       "92   http://www.en.netralnews.com/news/business/rea...  \n",
       "100  https://english.vietnamnet.vn/fms/business/207...  \n",
       "103  https://www.opengovasia.com/article/the-role-o...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_incom_2018 = pd.concat([data_incom, data_null])\n",
    "data_incom_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data_incom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sglinks.com                     20\n",
       "economictimes.indiatimes.com     5\n",
       "www.opengovasia.com              4\n",
       "www.chinamoneynetwork.com        3\n",
       "www.thepresidentpost.com         3\n",
       "www.prnewswire.com               2\n",
       "www.en.netralnews.com            1\n",
       "www.thepaypers.com               1\n",
       "www.finanzen.ch                  1\n",
       "inc42.com                        1\n",
       "www.bankingtech.com              1\n",
       "www.oann.com                     1\n",
       "english.vietnamnet.vn            1\n",
       "www.theedgemarkets.com           1\n",
       "www.gulf-times.com               1\n",
       "www.nytimes.com                  1\n",
       "www.infotechlead.com             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of troublesome domain link\n",
    "import urllib\n",
    "\n",
    "data_sourceurl = data_incom_2018['SOURCEURL']\n",
    "list_link = []\n",
    "\n",
    "# for extracting domain url. Example: \n",
    "# http://fintechnews.sg/25313/blockchain/blockchain-indonesia/ --> fintechnews.sg\n",
    "for link in data_sourceurl:\n",
    "    list_link.append(urllib.parse.urlparse(link).netloc)\n",
    "    \n",
    "data_link = pd.Series(list_link)\n",
    "\n",
    "# Count by its occurences\n",
    "data_link_count = data_link.value_counts()\n",
    "data_link_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save data\n",
    "data_startup.to_csv('data-startup-berita.csv', sep=';')\n",
    "data_incom_2018.to_csv('data-incom.csv', sep=';')\n",
    "\n",
    "# To read data\n",
    "# data_startup = pd.read_csv('data-startup-berita.csv', sep=';')\n",
    "# data_incom = pd.read_csv('data-incom.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of web scraper function\n",
    "\n",
    "# handling bankingtech.com\n",
    "def bankingtech_scrape(link):\n",
    "    import urllib\n",
    "    r = urllib.request.Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    web_byte = urllib.request.urlopen(r).read()\n",
    "    webpage = web_byte.decode('utf-8')\n",
    "        \n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(webpage,\"lxml\")\n",
    "    article = soup.find(\"div\", \"columns small-12 single-post-content_text-container\").text.strip()\n",
    "    return article\n",
    "\n",
    "# handling economictimes.indiatimes.com\n",
    "def economictimes_scrape(link):\n",
    "    import urllib\n",
    "    r = urllib.request.Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    web_byte = urllib.request.urlopen(r).read()\n",
    "    webpage = web_byte.decode('utf-8')\n",
    "        \n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(webpage,\"lxml\")\n",
    "    article = soup.find('div', 'Normal').text.strip()\n",
    "    return article\n",
    "\n",
    "# handling finanzen.ch\n",
    "def finanzen_scrape(link):\n",
    "    import urllib\n",
    "    r = urllib.request.Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    web_byte = urllib.request.urlopen(r).read()\n",
    "    webpage = web_byte.decode('utf-8')\n",
    "        \n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(webpage,\"lxml\")\n",
    "    article = soup.find(\"div\", \"col-md-12 col-xs-12 news-content\").text.strip()\n",
    "    article = article.split(\"if (\")\n",
    "    return article[0]\n",
    "\n",
    "# handling gulf-times.com\n",
    "def gulftimes_scrape(link):\n",
    "    import urllib\n",
    "    r = urllib.request.Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    web_byte = urllib.request.urlopen(r).read()\n",
    "    webpage = web_byte.decode('utf-8')\n",
    "        \n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(webpage,\"lxml\")\n",
    "    article = soup.find(\"div\", \"txtwrapper\").text.strip()\n",
    "    article = article.split(\");\\n\")\n",
    "    return article[2]\n",
    "\n",
    "# handling netralnews.com\n",
    "def netralnews_scrape(link):\n",
    "    import ssl\n",
    "    import urllib\n",
    "    import re\n",
    "    \n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    r = urllib.request.urlopen(link).read()\n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "    article = soup.find(\"div\",\"td-post-content\").text.strip()\n",
    "    article = article.split(\"};\\n\")\n",
    "    return article[1]\n",
    "\n",
    "# handling opengovasia.com\n",
    "def opengovasia_scrape(link):\n",
    "    import urllib\n",
    "    r = urllib.request.Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    web_byte = urllib.request.urlopen(r).read()\n",
    "    webpage = web_byte.decode('utf-8')\n",
    "        \n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(webpage,\"lxml\")\n",
    "    article = soup.find(\"div\", \"articlepage-body w-richtext\").text.strip()\n",
    "    return article\n",
    "\n",
    "# handling prnewswire.com\n",
    "def prnewswire_scrape(link):\n",
    "    import ssl\n",
    "    import urllib\n",
    "    \n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    r = urllib.request.urlopen(link).read()\n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "    element = soup.find_all(\"div\", \"col-sm-10 col-sm-offset-1\")\n",
    "    article = element[1].text.strip()\n",
    "    return article\n",
    "\n",
    "# handling thepaypers.com\n",
    "def thepaypers_scrape(link):\n",
    "    import urllib\n",
    "    r = urllib.request.Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    web_byte = urllib.request.urlopen(r).read()\n",
    "    webpage = web_byte.decode('utf-8')\n",
    "        \n",
    "    from bs4 import BeautifulSoup \n",
    "\n",
    "    soup = BeautifulSoup(webpage,\"lxml\")\n",
    "    article = soup.find(\"div\", \"noColumns\").text.strip()\n",
    "    return article\n",
    "\n",
    "# handling vietnamnet.com\n",
    "def vietnamnet_scrape(link):\n",
    "    import ssl\n",
    "    import urllib\n",
    "    \n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    r = urllib.request.urlopen(link).read()\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "    article = soup.find(\"div\",\"article_content\").text.strip()\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBALEVENTID</th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>Year</th>\n",
       "      <th>SOURCEURL</th>\n",
       "      <th>ARTICLEURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732482164</td>\n",
       "      <td>20180220</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/pages/110117536-tech-in-asi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>742227202</td>\n",
       "      <td>20180327</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/pages/111797193-tech-in-asi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>774333479</td>\n",
       "      <td>20180724</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/pages/116649609-tech-in-asi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721502576</td>\n",
       "      <td>20180111</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/startups/pages/108124290-hu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722354235</td>\n",
       "      <td>20180115</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://sglinks.com/startups/pages/108315380-cr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLOBALEVENTID   SQLDATE  Year  \\\n",
       "0      732482164  20180220  2018   \n",
       "1      742227202  20180327  2018   \n",
       "2      774333479  20180724  2018   \n",
       "3      721502576  20180111  2018   \n",
       "4      722354235  20180115  2018   \n",
       "\n",
       "                                           SOURCEURL ARTICLEURL  \n",
       "0  http://sglinks.com/pages/110117536-tech-in-asi...        NaN  \n",
       "1  http://sglinks.com/pages/111797193-tech-in-asi...        NaN  \n",
       "2  http://sglinks.com/pages/116649609-tech-in-asi...        NaN  \n",
       "3  http://sglinks.com/startups/pages/108124290-hu...        NaN  \n",
       "4  http://sglinks.com/startups/pages/108315380-cr...        NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV with trouble data\n",
    "data_trouble = pd.read_csv(\"data-incom-error-2018.csv\", sep=\";\")\n",
    "data_trouble = data_trouble.drop(['Column1','Status'], axis=1)\n",
    "data_trouble.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 5)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erase trouble data from dataset\n",
    "data_startup_clear = pd.DataFrame()\n",
    "data_startup_clear = pd.concat([data_startup, data_trouble])\n",
    "data_startup_clear.drop_duplicates(\"SOURCEURL\", keep = False, inplace=True)\n",
    "data_startup_clear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting http://www.bankingtech.com/2018/01/fintech-funding-round-up-23-january-2018/\n",
      "Extracting http://www.en.netralnews.com/news/business/read/24175/govt.partners.with.two.national.marketplaces.to.boost.indonesian.exports\n",
      "Extracting http://www.gulf-times.com/story/599050/A-new-term-is-born-Shariah-fintech-and-it-has-quit\n",
      "Extracting https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/alibabas-jack-ma-to-open-institute-for-tech-entrepreneurs-in-indonesia/articleshow/66193099.cms\n",
      "Extracting https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/faasos-in-talks-to-raise-100-million-for-expansion/articleshow/66280493.cms\n",
      "Extracting https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/google-says-invests-in-indonesian-ride-hailing-firm-go-jek/articleshow/62690817.cms\n",
      "Error scraping article https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/google-says-invests-in-indonesian-ride-hailing-firm-go-jek/articleshow/62690817.cms\n",
      "Extracting https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/ride-hailing-firm-grab-hits-back-in-uber-takeover-row/articleshow/65163091.cms\n",
      "Error scraping article https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/ride-hailing-firm-grab-hits-back-in-uber-takeover-row/articleshow/65163091.cms\n",
      "Extracting https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/ubers-exit-from-sounteast-asia-upsets-regulators-and-drivers/articleshow/64363937.cms\n",
      "Error scraping article https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/ubers-exit-from-sounteast-asia-upsets-regulators-and-drivers/articleshow/64363937.cms\n",
      "Extracting https://english.vietnamnet.vn/fms/business/207956/fintech-primed-to-boost-financial-services-sector-in-vietnam.html\n",
      "Extracting https://www.finanzen.ch/nachrichten/aktien/CEO-SUITE-Unveils-the-First-Ever-Collaboration-with-Accelerator-to-Help-Local-Startups-Going-Global-1027329705\n",
      "Extracting https://www.opengovasia.com/articles/australia-and-uk-set-up-fintech-bridge-to-deepen-collaboration-between-governments-regulators-and-industry-bodies\n",
      "Extracting https://www.opengovasia.com/articles/indonesia-to-produce-talents-with-coding-knowledge-through-the-del-arrbey-coding-and-start-up-academy\n",
      "Extracting https://www.opengovasia.com/indonesia-furthers-e-commerce-and-innovation/\n",
      "Extracting https://www.prnewswire.com/news-releases/nuctech-participates-at-the-1st-global-cross-border-e-commerce-conference-300609935.html\n",
      "Extracting https://www.prnewswire.com/news-releases/smartag-international-signs-agreement-to-provide-fintech-solutions-to-rural-indonesia-300606773.html\n",
      "Extracting https://www.thepaypers.com/mobile-payments/jd-com-allegedly-invests-in-indonesia-based-startup-go-jek/774551-16\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "# Load dataset that requires manual scraping\n",
    "data_startup_manual = pd.read_csv(\"data-incom-OK-2018.csv\", sep=\";\")\n",
    "data_startup_manual = data_startup_manual.drop(['Column1','Status'], axis=1)\n",
    "article_content = list()\n",
    "for link in data_startup_manual[\"SOURCEURL\"]:\n",
    "    domain = urllib.parse.urlparse(link).netloc\n",
    "    try:\n",
    "        print(\"Extracting \" + link)\n",
    "        if domain == \"economictimes.indiatimes.com\":\n",
    "            article_content.append(economictimes_scrape(link))\n",
    "        elif domain == \"www.opengovasia.com\":\n",
    "            article_content.append(opengovasia_scrape(link))\n",
    "        elif domain == \"www.en.netralnews.com\":\n",
    "            article_content.append(netralnews_scrape(link))\n",
    "        elif domain == \"www.gulf-times.com\":\n",
    "            article_content.append(gulftimes_scrape(link))\n",
    "        elif domain == \"www.bankingtech.com\":\n",
    "            article_content.append(bankingtech_scrape(link))\n",
    "        elif domain == \"english.vietnamnet.vn\":\n",
    "            article_content.append(vietnamnet_scrape(link))\n",
    "        elif domain == \"www.finanzen.ch\":\n",
    "            article_content.append(finanzen_scrape(link))\n",
    "        elif domain == \"www.opengovasia.com\":\n",
    "            article_content.append(opengovasia_scrape(link))\n",
    "        elif domain == \"www.prnewswire.com\":\n",
    "            article_content.append(prnewswire_scrape(link))\n",
    "        elif domain == \"www.thepaypers.com\":\n",
    "            article_content.append(thepaypers_scrape(link))\n",
    "        else:\n",
    "            article_content.append(\"\")\n",
    "    \n",
    "    except:\n",
    "        print(\"Error scraping article \" + link)\n",
    "        article_content.append(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBALEVENTID</th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>Year</th>\n",
       "      <th>SOURCEURL</th>\n",
       "      <th>ARTICLEURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>724739939</td>\n",
       "      <td>20180123</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://www.bankingtech.com/2018/01/fintech-fun...</td>\n",
       "      <td>Straight after the fintech funding round-up on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>785918381</td>\n",
       "      <td>20180910</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://www.en.netralnews.com/news/business/rea...</td>\n",
       "      <td>\\n\\nJAKARTA, NNC – The Ministry of Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770916157</td>\n",
       "      <td>20180710</td>\n",
       "      <td>2018</td>\n",
       "      <td>http://www.gulf-times.com/story/599050/A-new-t...</td>\n",
       "      <td>Indonesia’s Deputy Finance Minister Mardiasmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>794276788</td>\n",
       "      <td>20181013</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "      <td>NUSA DUA: Jack Ma, executive chairman of China...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>795776971</td>\n",
       "      <td>20180919</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://economictimes.indiatimes.com/small-biz...</td>\n",
       "      <td>NEW DELHI: Rebel Foods, owneroperator of inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>784607887</td>\n",
       "      <td>20180905</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://english.vietnamnet.vn/fms/business/207...</td>\n",
       "      <td>Vietnam is making strong policy moves to bolst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>768164766</td>\n",
       "      <td>20180629</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.finanzen.ch/nachrichten/aktien/CEO...</td>\n",
       "      <td>JAKARTA, Indonesia, June 29, 2018 /PRNewswire/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>742160946</td>\n",
       "      <td>20180326</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.opengovasia.com/articles/australia...</td>\n",
       "      <td>The Australian Treasurer, the Hon Scott Morris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>761694582</td>\n",
       "      <td>20180605</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.opengovasia.com/articles/indonesia...</td>\n",
       "      <td>An announcement\\nmade by the Ministry\\nof Comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>786997689</td>\n",
       "      <td>20180914</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.opengovasia.com/indonesia-furthers...</td>\n",
       "      <td>According to a recent report, Indonesia is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>736669068</td>\n",
       "      <td>20180307</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/nucte...</td>\n",
       "      <td>BEIJING, March 7, 2018 /PRNewswire/ -- From Fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>735066750</td>\n",
       "      <td>20180301</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/smart...</td>\n",
       "      <td>LAS VEGAS, March 1, 2018 /PRNewswire/ -- Smart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>782319837</td>\n",
       "      <td>20180827</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.thepaypers.com/mobile-payments/jd-...</td>\n",
       "      <td>JD.com has allegedly invested in Indonesia-bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GLOBALEVENTID   SQLDATE  Year  \\\n",
       "0       724739939  20180123  2018   \n",
       "1       785918381  20180910  2018   \n",
       "2       770916157  20180710  2018   \n",
       "3       794276788  20181013  2018   \n",
       "4       795776971  20180919  2018   \n",
       "8       784607887  20180905  2018   \n",
       "9       768164766  20180629  2018   \n",
       "10      742160946  20180326  2018   \n",
       "11      761694582  20180605  2018   \n",
       "12      786997689  20180914  2018   \n",
       "13      736669068  20180307  2018   \n",
       "14      735066750  20180301  2018   \n",
       "15      782319837  20180827  2018   \n",
       "\n",
       "                                            SOURCEURL  \\\n",
       "0   http://www.bankingtech.com/2018/01/fintech-fun...   \n",
       "1   http://www.en.netralnews.com/news/business/rea...   \n",
       "2   http://www.gulf-times.com/story/599050/A-new-t...   \n",
       "3   https://economictimes.indiatimes.com/small-biz...   \n",
       "4   https://economictimes.indiatimes.com/small-biz...   \n",
       "8   https://english.vietnamnet.vn/fms/business/207...   \n",
       "9   https://www.finanzen.ch/nachrichten/aktien/CEO...   \n",
       "10  https://www.opengovasia.com/articles/australia...   \n",
       "11  https://www.opengovasia.com/articles/indonesia...   \n",
       "12  https://www.opengovasia.com/indonesia-furthers...   \n",
       "13  https://www.prnewswire.com/news-releases/nucte...   \n",
       "14  https://www.prnewswire.com/news-releases/smart...   \n",
       "15  https://www.thepaypers.com/mobile-payments/jd-...   \n",
       "\n",
       "                                           ARTICLEURL  \n",
       "0   Straight after the fintech funding round-up on...  \n",
       "1           \\n\\nJAKARTA, NNC – The Ministry of Tra...  \n",
       "2    Indonesia’s Deputy Finance Minister Mardiasmo...  \n",
       "3   NUSA DUA: Jack Ma, executive chairman of China...  \n",
       "4   NEW DELHI: Rebel Foods, owneroperator of inter...  \n",
       "8   Vietnam is making strong policy moves to bolst...  \n",
       "9   JAKARTA, Indonesia, June 29, 2018 /PRNewswire/...  \n",
       "10  The Australian Treasurer, the Hon Scott Morris...  \n",
       "11  An announcement\\nmade by the Ministry\\nof Comm...  \n",
       "12  According to a recent report, Indonesia is the...  \n",
       "13  BEIJING, March 7, 2018 /PRNewswire/ -- From Fe...  \n",
       "14  LAS VEGAS, March 1, 2018 /PRNewswire/ -- Smart...  \n",
       "15  JD.com has allegedly invested in Indonesia-bas...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there is 404 error passed, then let's clean\n",
    "data_startup_manual[\"ARTICLEURL\"] = pd.Series(article_content)\n",
    "data_startup_manual_ok = data_startup_manual[data_startup_manual[\"ARTICLEURL\"] != \"\"]\n",
    "data_startup_manual_ok\n",
    "# # forget to remove column1 and status\n",
    "# data_startup_manual_ok = data_startup_manual_ok.drop(['Column1','Status'], axis=1)\n",
    "# data_startup_manual_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add scraped data to startup\n",
    "data_startup_clear = pd.concat([data_startup_clear, data_startup_manual])\n",
    "data_startup_clear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just for making sure\n",
    "data_clear = data_startup_clear[data_startup_clear[\"ARTICLEURL\"] != data_startup_clear[\"SOURCEURL\"]]\n",
    "data_clear = data_clear[data_clear[\"ARTICLEURL\"] != \"\"]\n",
    "data_clear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it for future use\n",
    "data_clear.to_csv(\"data-clear-2018.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x94\\\\x8A L...' for column 'ARTICLEURL' at row 107\")\n",
      "  result = self._query(query)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xEF\\\\xBB\\\\xBF\\\\x0A\\\\x0AJ...' for column 'ARTICLEURL' at row 108\")\n",
      "  result = self._query(query)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xE2\\\\x80\\\\x8EGoo...' for column 'ARTICLEURL' at row 238\")\n",
      "  result = self._query(query)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xE2\\\\x82\\\\xB93,5...' for column 'ARTICLEURL' at row 243\")\n",
      "  result = self._query(query)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, 'Incorrect string value: \\'\\\\xE2\\\\x80\\\\x8B: \"...\\' for column \\'ARTICLEURL\\' at row 256')\n",
      "  result = self._query(query)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x94\\\\x8A L...' for column 'ARTICLEURL' at row 18\")\n",
      "  result = self._query(query)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x94\\\\x8A L...' for column 'ARTICLEURL' at row 29\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "# Save non-duplicated data to 'article_startup_indonesia' table\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "username = 'root'\n",
    "password = ''\n",
    "database = 'gdelt_content_id'\n",
    "database_name = 'article_startup_indonesia'\n",
    "engine_s = create_engine('mysql+pymysql://'+username+':'+password+'@'+host+':'\n",
    "                         +port+'/'+database)\n",
    "data_clear.to_sql(database_name, engine_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
